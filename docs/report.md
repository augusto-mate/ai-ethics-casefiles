# ğŸ§¾ AI Ethics Casefiles â€” Report

_Augusto Mate, 2025_

---

## ğŸ“˜ Introduction

This case study explores two real-world AI systems through a lens of ethical analysis,
with a focus on bias, transparency, and fairness. The aim is to identify
problematic patterns and suggest responsible alternatives grounded in academic and real-world best practices.

---

## ğŸ“‚ Case 1: COMPAS â€” Algorithmic Risk Assessment 

> â€œPredicting recidivism isnâ€™t neutral when historical data is biased.â€

- **System**: COMPAS (Correctional Offender Management Profiling)
- **Context**: Used in U.S. courts to assess likelihood of reoffending
- **Ethical Issues**:
  - Racial bias in training data
  - Lack of transparency
  - Opaque decision logic

### Ethical Evaluation

Using principles from AI4People and the EU Ethics Guidelines, the COMPAS system fails in:

- **Fairness**: Reinforces systemic bias
- **Transparency**: Proprietary algorithm resists scrutiny
- **Accountability**: Judges rely on automated scores with minimal oversight

### Suggested Redesign

- Replace opaque scoring with interpretable models (e.g., logistic regression with weights shown)
- Require local explainability (e.g., SHAP values)
- Independent audits and open datasets

---

## ğŸ“ Case 2: Hiring Algorithm by Amazon (Discontinued)

> â€œAn algorithm trained on past hires mirrors past biases.â€

- **System**: Internal hiring tool used between 2014â€“2017
- **Problem**: Penalized resumes with â€œwomenâ€™sâ€ indicators (e.g., womenâ€™s college)
- **Outcome**: Discontinued after bias detection

### Ethical Evaluation

Fails in:

- **Justice and fairness**
- **Human oversight**
- **Inclusive design**

---

## ğŸ§­ Conclusion

AI systems, even unintentionally, can amplify existing biases and exclusions.
Ethical evaluations should not be afterthoughts, but foundational to system design.

### Key Takeaways

- Data is not neutral â€” neither are models
- Interpretability is key to transparency
- Accountability frameworks must exist beyond code

---

## ğŸ“š References

- AI4People (Floridi et al.)
- EU Ethics Guidelines for Trustworthy AI
- ProPublica (2016). Machine Bias.
